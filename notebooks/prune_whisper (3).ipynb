{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets transformers evaluate\n",
        "!pip install huggingface_hub\n",
        "!pip install jiwer\n",
        "!pip install bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQxxL-I0K_uJ",
        "outputId": "a1a9355e-cc2e-4896-a645-5ac98ba83048"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets, evaluate\n",
            "Successfully installed datasets-3.3.2 dill-0.3.8 evaluate-0.4.3 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\n",
            "Collecting jiwer\n",
            "  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
            "  Downloading rapidfuzz-3.12.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading jiwer-3.1.0-py3-none-any.whl (22 kB)\n",
            "Downloading rapidfuzz-3.12.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-3.1.0 rapidfuzz-3.12.2\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.5.1+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bitsandbytes-0.45.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qs859CdBKkuE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "from datasets import load_dataset, concatenate_datasets, Audio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration, AutoConfig, BitsAndBytesConfig\n",
        "import evaluate\n",
        "from bitsandbytes.nn import Int8Params, Params4bit\n",
        "import torch.nn.utils.prune as prune\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303,
          "referenced_widgets": [
            "85b218c708814b0b87e9b890b2e39f7d",
            "f1de4cc751f84c1a9d86c355fd7e65c7",
            "346de9b952274147a7ce6ccd0aa9d207",
            "9523ae69a81e4b5d9e6d9c0cbdec40db",
            "9e7f16824fc345adb93168f1bd3b0db8",
            "40aea8874d2243228d759818c65f43d2",
            "cc07cb72d2e84d9bb35ae3ef186d83b4",
            "e217b4328dc241dcad51b126cc7e3cdb",
            "d15d4a89e24846a581601e225ce8638f",
            "9d74ec1fc30a45fa98b7e80828e4cfdc",
            "a13b62b212764d3ca1a9b40a7c07b828",
            "d3b40884c87949c98e45c08e8e8f018a",
            "190448ea81544b839de18f0bce9a065b",
            "9ff63ccde3b447c3bdcbdb3c8029475b",
            "29d5183917ed46669e02fe4948e06845",
            "13de90f54251461a9ef73e3ab0b11aa2",
            "8ab6ccaa3d614bdd8b5d14d55af37b47"
          ]
        },
        "id": "dQv5JEjuKkuG",
        "outputId": "fca71356-34d0-4294-ebfc-a63171e0fe4f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85b218c708814b0b87e9b890b2e39f7d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# from huggingface_hub import notebook_login\n",
        "\n",
        "# # This will display a widget to login interactively\n",
        "# notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlx0v4DAKkuG",
        "outputId": "ca5df989-d592-45c4-9616-928e86bd0179"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 16372it [00:00, 40280.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "en: Got 74 male and 74 female samples\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "\n",
        "def get_balanced_sample(lang_code, max_samples=500):\n",
        "    \"\"\"Get a small gender-balanced sample for a language\"\"\"\n",
        "\n",
        "    # Load dataset in streaming mode\n",
        "    stream_dataset = load_dataset(\"mozilla-foundation/common_voice_13_0\", lang_code, split=\"validation\", streaming=True)\n",
        "\n",
        "    # Filter samples with gender info\n",
        "    filtered_dataset = (x for x in stream_dataset if x[\"gender\"] in [\"male\", \"female\"])\n",
        "\n",
        "    # Collect up to max_samples items\n",
        "    dataset = []\n",
        "    for sample in filtered_dataset:\n",
        "        if len(dataset) >= max_samples:\n",
        "            break\n",
        "        dataset.append(sample)\n",
        "\n",
        "    # Separate by gender\n",
        "    male_samples = [x for x in dataset if x[\"gender\"] == \"male\"]\n",
        "    female_samples = [x for x in dataset if x[\"gender\"] == \"female\"]\n",
        "\n",
        "    # Get balanced samples (up to max_samples/2 from each gender)\n",
        "    max_per_gender = min(len(male_samples), len(female_samples), max_samples // 2)\n",
        "\n",
        "    male_balanced = male_samples[:max_per_gender]\n",
        "    female_balanced = female_samples[:max_per_gender]\n",
        "\n",
        "    # Combine and return\n",
        "    results = {\n",
        "        \"male\": male_balanced,\n",
        "        \"female\": female_balanced\n",
        "    }\n",
        "\n",
        "    print(f\"{lang_code}: Got {len(male_balanced)} male and {len(female_balanced)} female samples\")\n",
        "    return results\n",
        "\n",
        "# Test with a few languages\n",
        "languages = [\"en\", \"es\", \"fr\"]\n",
        "languages = [\"en\"]\n",
        "samples = {}\n",
        "\n",
        "for lang in languages:\n",
        "    samples[lang] = get_balanced_sample(lang)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "6zMUc9lnKkuG",
        "outputId": "a5a88e63-7eff-46a0-f835-4ded37cebda9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 16372it [00:00, 73367.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "en: 100 male, 100 female samples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading metadata...: 15708it [00:00, 67465.52it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-48362a7812a2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mlanguages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"es\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mbalanced_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprepare_gender_balanced_data_streaming\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlanguages\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-48362a7812a2>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mlanguages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"es\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mbalanced_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprepare_gender_balanced_data_streaming\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlanguages\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-48362a7812a2>\u001b[0m in \u001b[0;36mprepare_gender_balanced_data_streaming\u001b[0;34m(lang_code, max_samples)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmale_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfemale_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiltered_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gender\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"male\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmale_samples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_samples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mmale_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-48362a7812a2>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Filter samples with gender info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mfiltered_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gender\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"male\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"female\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Collect up to max_samples items\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/iterable_dataset.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2228\u001b[0m                 \u001b[0;31m# `IterableDataset` automatically fills missing columns with None.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2229\u001b[0m                 \u001b[0;31m# This is done with `_apply_feature_types_on_example`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2230\u001b[0;31m                 example = _apply_feature_types_on_example(\n\u001b[0m\u001b[1;32m   2231\u001b[0m                     \u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_token_per_repo_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/iterable_dataset.py\u001b[0m in \u001b[0;36m_apply_feature_types_on_example\u001b[0;34m(example, features, token_per_repo_id)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0mencoded_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m     \u001b[0;31m# Decode example for Audio feature, e.g.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m     \u001b[0mdecoded_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_example\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecoded_example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/features/features.py\u001b[0m in \u001b[0;36mdecode_example\u001b[0;34m(self, example, token_per_repo_id)\u001b[0m\n\u001b[1;32m   2046\u001b[0m         \"\"\"\n\u001b[1;32m   2047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2048\u001b[0;31m         return {\n\u001b[0m\u001b[1;32m   2049\u001b[0m             \u001b[0mcolumn_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdecode_nested_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2050\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_column_requires_decoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/features/features.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2048\u001b[0m         return {\n\u001b[0;32m-> 2049\u001b[0;31m             \u001b[0mcolumn_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdecode_nested_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2050\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_column_requires_decoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2051\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/features/features.py\u001b[0m in \u001b[0;36mdecode_nested_example\u001b[0;34m(schema, obj, token_per_repo_id)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"decode_example\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"decode\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0;31m# we pass the token to read and decode files from private repositories in streaming mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/features/audio.py\u001b[0m in \u001b[0;36mdecode_example\u001b[0;34m(self, value, token_per_repo_id)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/soundfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(file, frames, start, stop, dtype, always_2d, fill_value, out, samplerate, channels, format, subtype, endian, closefd)\u001b[0m\n\u001b[1;32m    306\u001b[0m                    subtype, endian, format, closefd) as f:\n\u001b[1;32m    307\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malways_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/soundfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, frames, dtype, always_2d, fill_value, out)\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m             \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_empty_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malways_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mframes\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mframes\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_create_empty_array\u001b[0;34m(self, frames, always_2d, dtype)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m             \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# from datasets import load_dataset\n",
        "\n",
        "# def prepare_gender_balanced_data_streaming(lang_code, max_samples=200):\n",
        "#     \"\"\"Create a gender-balanced dataset in streaming mode.\"\"\"\n",
        "#     dataset = load_dataset(\"mozilla-foundation/common_voice_13_0\", lang_code, split=\"validation\", streaming=True)\n",
        "\n",
        "#     # Filter samples with gender info\n",
        "#     filtered_dataset = (x for x in dataset if x[\"gender\"] in [\"male\", \"female\"])\n",
        "\n",
        "#     # Collect up to max_samples items\n",
        "#     male_samples, female_samples = [], []\n",
        "\n",
        "#     for sample in filtered_dataset:\n",
        "#         if sample[\"gender\"] == \"male\" and len(male_samples) < max_samples // 2:\n",
        "#             male_samples.append(sample)\n",
        "#         elif sample[\"gender\"] == \"female\" and len(female_samples) < max_samples // 2:\n",
        "#             female_samples.append(sample)\n",
        "\n",
        "#         if len(male_samples) >= max_samples // 2 and len(female_samples) >= max_samples // 2:\n",
        "#             break  # Stop collecting once balanced\n",
        "\n",
        "#     print(f\"{lang_code}: {len(male_samples)} male, {len(female_samples)} female samples\")\n",
        "\n",
        "#     return {\n",
        "#         \"male\": male_samples,\n",
        "#         \"female\": female_samples,\n",
        "#         \"combined\": male_samples + female_samples\n",
        "#     }\n",
        "\n",
        "# # Example usage\n",
        "# languages = [\"en\", \"es\", \"fr\"]\n",
        "# balanced_datasets = {lang: prepare_gender_balanced_data_streaming(lang) for lang in languages}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJVsZvjPKkuG",
        "outputId": "9cc23dfe-0099-46da-e791-744d77a614c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
            "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded with 8bit precision on cuda\n",
            "Model dtype after loading: torch.float16\n",
            "Layer model.encoder.layers.0.self_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.0.self_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.0.self_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.0.self_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.0.fc1.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.0.fc2.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.1.self_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.1.self_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.1.self_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.1.self_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.1.fc1.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.1.fc2.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.2.self_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.2.self_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.2.self_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.2.self_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.2.fc1.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.2.fc2.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.3.self_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.3.self_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.3.self_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.3.self_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.3.fc1.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.3.fc2.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.4.self_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.4.self_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.4.self_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.4.self_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.4.fc1.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.4.fc2.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.5.self_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.5.self_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.5.self_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.5.self_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.5.fc1.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.5.fc2.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.6.self_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.6.self_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.6.self_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.6.self_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.6.fc1.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.6.fc2.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.7.self_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.7.self_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.7.self_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.7.self_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.7.fc1.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.7.fc2.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.8.self_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.8.self_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.8.self_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.8.self_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.8.fc1.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.8.fc2.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.9.self_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.9.self_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.9.self_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.9.self_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.9.fc1.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.9.fc2.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.10.self_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.10.self_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.10.self_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.10.self_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.10.fc1.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.10.fc2.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.11.self_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.11.self_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.11.self_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.11.self_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.11.fc1.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.encoder.layers.11.fc2.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.0.self_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.0.self_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.0.self_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.0.self_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.0.encoder_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.0.encoder_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.0.encoder_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.0.encoder_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.0.fc1.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.0.fc2.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.1.self_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.1.self_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.1.self_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.1.self_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.1.encoder_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.1.encoder_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.1.encoder_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.1.encoder_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.1.fc1.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.1.fc2.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.2.self_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.2.self_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.2.self_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.2.self_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.2.encoder_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.2.encoder_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.2.encoder_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.2.encoder_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.2.fc1.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.2.fc2.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.3.self_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.3.self_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.3.self_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.3.self_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.3.encoder_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.3.encoder_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.3.encoder_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.3.encoder_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.3.fc1.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.3.fc2.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.4.self_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.4.self_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.4.self_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.4.self_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.4.encoder_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.4.encoder_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.4.encoder_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.4.encoder_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.4.fc1.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.4.fc2.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.5.self_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.5.self_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.5.self_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.5.self_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.5.encoder_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.5.encoder_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.5.encoder_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.5.encoder_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.5.fc1.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.5.fc2.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.6.self_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.6.self_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.6.self_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.6.self_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.6.encoder_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.6.encoder_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.6.encoder_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.6.encoder_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.6.fc1.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.6.fc2.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.7.self_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.7.self_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.7.self_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.7.self_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.7.encoder_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.7.encoder_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.7.encoder_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.7.encoder_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.7.fc1.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.7.fc2.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.8.self_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.8.self_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.8.self_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.8.self_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.8.encoder_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.8.encoder_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.8.encoder_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.8.encoder_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.8.fc1.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.8.fc2.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.9.self_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.9.self_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.9.self_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.9.self_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.9.encoder_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.9.encoder_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.9.encoder_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.9.encoder_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.9.fc1.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.9.fc2.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.10.self_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.10.self_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.10.self_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.10.self_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.10.encoder_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.10.encoder_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.10.encoder_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.10.encoder_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.10.fc1.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.10.fc2.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.11.self_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.11.self_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.11.self_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.11.self_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.11.encoder_attn.k_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.11.encoder_attn.v_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.11.encoder_attn.q_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.11.encoder_attn.out_proj.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.11.fc1.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Layer model.decoder.layers.11.fc2.weight is quantized with <class 'bitsandbytes.nn.modules.Int8Params'>\n",
            "Memory allocated: 3216.53248 MB\n",
            "Device: cuda\n",
            "Creating pruned model with 30.0% pruning...\n",
            "Model dtype after pruning: torch.float16\n",
            "Creating pruned model with 50.0% pruning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model dtype after pruning: torch.float16\n"
          ]
        }
      ],
      "source": [
        "from bitsandbytes.nn import Int8Params, Params4bit\n",
        "\n",
        "# Load Whisper model (small to start with, as in the paper)\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")  # Use MPS on macOS\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")  # Use CUDA on compatible GPUs\n",
        "else:\n",
        "    device = torch.device(\"cpu\")  # Default to CPU\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model_id = \"openai/whisper-small\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define precision options\n",
        "fp_precision = \"8bit\"  # Change to \"8bit\", \"4bit\", or \"32bit\" as needed\n",
        "precision_map = {\n",
        "    \"32bit\": torch.float32,\n",
        "    \"16bit\": torch.float16,\n",
        "    \"bf16\": torch.bfloat16\n",
        "}\n",
        "\n",
        "# Load processor\n",
        "processor = WhisperProcessor.from_pretrained(model_id)\n",
        "\n",
        "if torch.backends.mps.is_available() and fp_precision in [\"8bit\", \"4bit\"]:\n",
        "    raise ValueError(\"bitsandbytes 8-bit and 4-bit quantization is not supported on Apple MPS. Please use '16bit' or '32bit' instead.\")\n",
        "\n",
        "# Handle 8-bit and 4-bit quantization separately\n",
        "if fp_precision in [\"8bit\", \"4bit\"]:\n",
        "    use_4bit = fp_precision == \"4bit\"\n",
        "    quantization_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=use_4bit,\n",
        "        load_in_8bit=not use_4bit,\n",
        "        bnb_4bit_compute_dtype=torch.float16 if use_4bit else None,\n",
        "        bnb_4bit_use_double_quant=use_4bit\n",
        "    )\n",
        "\n",
        "    # Load model with quantization\n",
        "    model = WhisperForConditionalGeneration.from_pretrained(\n",
        "        model_id,\n",
        "        quantization_config=quantization_config\n",
        "    )\n",
        "else:\n",
        "    # Load model with specified precision\n",
        "    torch_dtype = precision_map.get(fp_precision, torch.float32)\n",
        "    model = WhisperForConditionalGeneration.from_pretrained(\n",
        "        model_id,\n",
        "        torch_dtype=torch_dtype\n",
        "    )\n",
        "\n",
        "# Move to device if not quantized (bnb models stay on GPU automatically)\n",
        "if fp_precision not in [\"8bit\", \"4bit\"]:\n",
        "    model = model.to(device)\n",
        "\n",
        "print(f\"Model loaded with {fp_precision} precision on {device}\")\n",
        "# print(f\"Precision: {precision}\")\n",
        "print(f\"Model dtype after loading: {next(model.parameters()).dtype}\")\n",
        "\n",
        "# Print details about quantized layers\n",
        "for name, param in model.named_parameters():\n",
        "    if isinstance(param, (Int8Params, Params4bit)):\n",
        "        print(f\"Layer {name} is quantized with {type(param)}\")\n",
        "\n",
        "print(f\"Memory allocated: {torch.cuda.memory_allocated() / 1e6} MB\")\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "import torch.nn.utils.prune as prune\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "def apply_magnitude_pruning(model, amount=0.3, fp_precision=\"16bit\"):\n",
        "    \"\"\"Apply magnitude pruning to Conv and Linear layers, maintaining precision.\"\"\"\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, torch.nn.Conv1d) or isinstance(module, torch.nn.Linear):\n",
        "            prune.l1_unstructured(module, name='weight', amount=amount)\n",
        "            # Make pruning permanent\n",
        "            prune.remove(module, 'weight')\n",
        "\n",
        "            # Ensure weight remains in the correct precision\n",
        "            if fp_precision == \"16bit\":\n",
        "                module.weight.data = module.weight.data.to(torch.float16)\n",
        "            elif fp_precision == \"8bit\" or fp_precision == \"4bit\":\n",
        "                module.weight.data = module.weight.data.to(torch.float32)  # BnB handles quantization itself\n",
        "\n",
        "    return model\n",
        "\n",
        "pruning_levels = [0, 0.3, 0.5]  # 0 means original model\n",
        "pruned_models = {}\n",
        "\n",
        "for level in pruning_levels:\n",
        "    if level == 0:\n",
        "        pruned_models[level] = model\n",
        "    else:\n",
        "        print(f\"Creating pruned model with {level*100}% pruning...\")\n",
        "\n",
        "        if fp_precision in [\"8bit\", \"4bit\"]:\n",
        "            use_4bit = fp_precision == \"4bit\"\n",
        "            quantization_config = BitsAndBytesConfig(\n",
        "                load_in_4bit=use_4bit,\n",
        "                load_in_8bit=not use_4bit,\n",
        "                bnb_4bit_compute_dtype=torch.float16 if use_4bit else None,\n",
        "                bnb_4bit_use_double_quant=use_4bit\n",
        "            )\n",
        "\n",
        "            # Reload in quantized format\n",
        "            pruned_models[level] = WhisperForConditionalGeneration.from_pretrained(\n",
        "                model_id,\n",
        "                quantization_config=quantization_config\n",
        "            )\n",
        "        else:\n",
        "            # Reload in correct precision (FP16 or FP32)\n",
        "            torch_dtype = torch.float16 if fp_precision == \"16bit\" else torch.float32\n",
        "            pruned_models[level] = WhisperForConditionalGeneration.from_pretrained(\n",
        "                model_id,\n",
        "                torch_dtype=torch_dtype\n",
        "            ).to(device)\n",
        "\n",
        "        # Apply pruning while keeping precision\n",
        "        pruned_models[level] = apply_magnitude_pruning(pruned_models[level], amount=level, fp_precision=fp_precision)\n",
        "\n",
        "        # Ensure model remains in the correct precision\n",
        "        if fp_precision == \"16bit\":\n",
        "            pruned_models[level] = pruned_models[level].half().to(device)\n",
        "\n",
        "        print(f\"Model dtype after pruning: {next(pruned_models[level].parameters()).dtype}\")\n",
        "        # print(f\"Memory allocated: {torch.cuda.memory_allocated() / 1e6} MB\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zg30zNBxKkuH",
        "outputId": "ccc7ca95-e3c6-4a27-808f-9e49d51fe536"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating en with pruning level 0...\n",
            "Processed 0 samples...\n",
            "Processed 1 samples...\n",
            "Processed 2 samples...\n",
            "Processed 3 samples...\n",
            "Processed 4 samples...\n",
            "Processed 5 samples...\n",
            "Processed 6 samples...\n",
            "Processed 7 samples...\n",
            "Processed 8 samples...\n",
            "Processed 9 samples...\n",
            "Processed 10 samples...\n",
            "Processed 11 samples...\n",
            "Processed 12 samples...\n",
            "Processed 13 samples...\n",
            "Processed 14 samples...\n",
            "Processed 15 samples...\n",
            "Processed 16 samples...\n",
            "Processed 17 samples...\n",
            "Processed 18 samples...\n",
            "Processed 19 samples...\n",
            "Processed 20 samples...\n",
            "Processed 21 samples...\n",
            "Processed 22 samples...\n",
            "Processed 23 samples...\n",
            "Processed 24 samples...\n",
            "Processed 25 samples...\n",
            "Processed 26 samples...\n",
            "Processed 27 samples...\n",
            "Processed 28 samples...\n",
            "Processed 29 samples...\n",
            "Processed 30 samples...\n",
            "Processed 31 samples...\n",
            "Processed 32 samples...\n",
            "Processed 33 samples...\n",
            "Processed 34 samples...\n",
            "Processed 35 samples...\n",
            "Processed 36 samples...\n",
            "Processed 37 samples...\n",
            "Processed 38 samples...\n",
            "Processed 39 samples...\n",
            "Processed 40 samples...\n",
            "Processed 41 samples...\n",
            "Processed 42 samples...\n",
            "Processed 43 samples...\n",
            "Processed 44 samples...\n",
            "Processed 45 samples...\n",
            "Processed 46 samples...\n",
            "Processed 47 samples...\n",
            "Processed 48 samples...\n",
            "Processed 49 samples...\n",
            "Processed 50 samples...\n",
            "Processed 51 samples...\n",
            "Processed 52 samples...\n",
            "Processed 53 samples...\n",
            "Processed 54 samples...\n",
            "Processed 55 samples...\n",
            "Processed 56 samples...\n",
            "Processed 57 samples...\n",
            "Processed 58 samples...\n",
            "Processed 59 samples...\n",
            "Processed 60 samples...\n",
            "Processed 61 samples...\n",
            "Processed 62 samples...\n",
            "Processed 63 samples...\n",
            "Processed 64 samples...\n",
            "Processed 65 samples...\n",
            "Processed 66 samples...\n",
            "Processed 67 samples...\n",
            "Processed 68 samples...\n",
            "Processed 69 samples...\n",
            "Processed 70 samples...\n",
            "Processed 71 samples...\n",
            "Processed 72 samples...\n",
            "Processed 73 samples...\n",
            "Processed 0 samples...\n",
            "Processed 1 samples...\n",
            "Processed 2 samples...\n",
            "Processed 3 samples...\n",
            "Processed 4 samples...\n",
            "Processed 5 samples...\n",
            "Processed 6 samples...\n",
            "Processed 7 samples...\n",
            "Processed 8 samples...\n",
            "Processed 9 samples...\n",
            "Processed 10 samples...\n",
            "Processed 11 samples...\n",
            "Processed 12 samples...\n",
            "Processed 13 samples...\n",
            "Processed 14 samples...\n",
            "Processed 15 samples...\n",
            "Processed 16 samples...\n",
            "Processed 17 samples...\n",
            "Processed 18 samples...\n",
            "Processed 19 samples...\n",
            "Processed 20 samples...\n",
            "Processed 21 samples...\n",
            "Processed 22 samples...\n",
            "Processed 23 samples...\n",
            "Processed 24 samples...\n",
            "Processed 25 samples...\n",
            "Processed 26 samples...\n",
            "Processed 27 samples...\n",
            "Processed 28 samples...\n",
            "Processed 29 samples...\n",
            "Processed 30 samples...\n",
            "Processed 31 samples...\n",
            "Processed 32 samples...\n",
            "Processed 33 samples...\n",
            "Processed 34 samples...\n",
            "Processed 35 samples...\n",
            "Processed 36 samples...\n",
            "Processed 37 samples...\n",
            "Processed 38 samples...\n",
            "Processed 39 samples...\n",
            "Processed 40 samples...\n",
            "Processed 41 samples...\n",
            "Processed 42 samples...\n",
            "Processed 43 samples...\n",
            "Processed 44 samples...\n",
            "Processed 45 samples...\n",
            "Processed 46 samples...\n",
            "Processed 47 samples...\n",
            "Processed 48 samples...\n",
            "Processed 49 samples...\n",
            "Processed 50 samples...\n",
            "Processed 51 samples...\n",
            "Processed 52 samples...\n",
            "Processed 53 samples...\n",
            "Processed 54 samples...\n",
            "Processed 55 samples...\n",
            "Processed 56 samples...\n",
            "Processed 57 samples...\n",
            "Processed 58 samples...\n",
            "Processed 59 samples...\n",
            "Processed 60 samples...\n",
            "Processed 61 samples...\n",
            "Processed 62 samples...\n",
            "Processed 63 samples...\n",
            "Processed 64 samples...\n",
            "Processed 65 samples...\n",
            "Processed 66 samples...\n",
            "Processed 67 samples...\n",
            "Processed 68 samples...\n",
            "Processed 69 samples...\n",
            "Processed 70 samples...\n",
            "Processed 71 samples...\n",
            "Processed 72 samples...\n",
            "Processed 73 samples...\n",
            "Evaluating en with pruning level 0.3...\n",
            "Processed 0 samples...\n",
            "Processed 1 samples...\n",
            "Processed 2 samples...\n",
            "Processed 3 samples...\n",
            "Processed 4 samples...\n",
            "Processed 5 samples...\n",
            "Processed 6 samples...\n",
            "Processed 7 samples...\n",
            "Processed 8 samples...\n",
            "Processed 9 samples...\n",
            "Processed 10 samples...\n",
            "Processed 11 samples...\n",
            "Processed 12 samples...\n",
            "Processed 13 samples...\n",
            "Processed 14 samples...\n",
            "Processed 15 samples...\n",
            "Processed 16 samples...\n",
            "Processed 17 samples...\n",
            "Processed 18 samples...\n",
            "Processed 19 samples...\n",
            "Processed 20 samples...\n",
            "Processed 21 samples...\n",
            "Processed 22 samples...\n",
            "Processed 23 samples...\n",
            "Processed 24 samples...\n",
            "Processed 25 samples...\n",
            "Processed 26 samples...\n",
            "Processed 27 samples...\n",
            "Processed 28 samples...\n",
            "Processed 29 samples...\n",
            "Processed 30 samples...\n",
            "Processed 31 samples...\n",
            "Processed 32 samples...\n",
            "Processed 33 samples...\n",
            "Processed 34 samples...\n",
            "Processed 35 samples...\n",
            "Processed 36 samples...\n",
            "Processed 37 samples...\n",
            "Processed 38 samples...\n",
            "Processed 39 samples...\n",
            "Processed 40 samples...\n",
            "Processed 41 samples...\n",
            "Processed 42 samples...\n",
            "Processed 43 samples...\n",
            "Processed 44 samples...\n",
            "Processed 45 samples...\n",
            "Processed 46 samples...\n",
            "Processed 47 samples...\n",
            "Processed 48 samples...\n",
            "Processed 49 samples...\n",
            "Processed 50 samples...\n",
            "Processed 51 samples...\n",
            "Processed 52 samples...\n",
            "Processed 53 samples...\n",
            "Processed 54 samples...\n",
            "Processed 55 samples...\n",
            "Processed 56 samples...\n",
            "Processed 57 samples...\n",
            "Processed 58 samples...\n",
            "Processed 59 samples...\n",
            "Processed 60 samples...\n",
            "Processed 61 samples...\n",
            "Processed 62 samples...\n",
            "Processed 63 samples...\n",
            "Processed 64 samples...\n",
            "Processed 65 samples...\n",
            "Processed 66 samples...\n",
            "Processed 67 samples...\n",
            "Processed 68 samples...\n",
            "Processed 69 samples...\n",
            "Processed 70 samples...\n",
            "Processed 71 samples...\n",
            "Processed 72 samples...\n",
            "Processed 73 samples...\n",
            "Processed 0 samples...\n",
            "Processed 1 samples...\n",
            "Processed 2 samples...\n",
            "Processed 3 samples...\n",
            "Processed 4 samples...\n",
            "Processed 5 samples...\n",
            "Processed 6 samples...\n",
            "Processed 7 samples...\n",
            "Processed 8 samples...\n",
            "Processed 9 samples...\n",
            "Processed 10 samples...\n",
            "Processed 11 samples...\n",
            "Processed 12 samples...\n",
            "Processed 13 samples...\n",
            "Processed 14 samples...\n",
            "Processed 15 samples...\n",
            "Processed 16 samples...\n",
            "Processed 17 samples...\n",
            "Processed 18 samples...\n",
            "Processed 19 samples...\n",
            "Processed 20 samples...\n",
            "Processed 21 samples...\n",
            "Processed 22 samples...\n",
            "Processed 23 samples...\n",
            "Processed 24 samples...\n",
            "Processed 25 samples...\n",
            "Processed 26 samples...\n",
            "Processed 27 samples...\n",
            "Processed 28 samples...\n",
            "Processed 29 samples...\n",
            "Processed 30 samples...\n",
            "Processed 31 samples...\n",
            "Processed 32 samples...\n",
            "Processed 33 samples...\n",
            "Processed 34 samples...\n",
            "Processed 35 samples...\n",
            "Processed 36 samples...\n",
            "Processed 37 samples...\n",
            "Processed 38 samples...\n",
            "Processed 39 samples...\n",
            "Processed 40 samples...\n",
            "Processed 41 samples...\n",
            "Processed 42 samples...\n",
            "Processed 43 samples...\n",
            "Processed 44 samples...\n",
            "Processed 45 samples...\n",
            "Processed 46 samples...\n",
            "Processed 47 samples...\n",
            "Processed 48 samples...\n",
            "Processed 49 samples...\n",
            "Processed 50 samples...\n",
            "Processed 51 samples...\n",
            "Processed 52 samples...\n",
            "Processed 53 samples...\n",
            "Processed 54 samples...\n",
            "Processed 55 samples...\n",
            "Processed 56 samples...\n",
            "Processed 57 samples...\n",
            "Processed 58 samples...\n",
            "Processed 59 samples...\n",
            "Processed 60 samples...\n",
            "Processed 61 samples...\n",
            "Processed 62 samples...\n",
            "Processed 63 samples...\n",
            "Processed 64 samples...\n",
            "Processed 65 samples...\n",
            "Processed 66 samples...\n",
            "Processed 67 samples...\n",
            "Processed 68 samples...\n",
            "Processed 69 samples...\n",
            "Processed 70 samples...\n",
            "Processed 71 samples...\n",
            "Processed 72 samples...\n",
            "Processed 73 samples...\n",
            "Evaluating en with pruning level 0.5...\n",
            "Processed 0 samples...\n",
            "Processed 1 samples...\n",
            "Processed 2 samples...\n",
            "Processed 3 samples...\n",
            "Processed 4 samples...\n",
            "Processed 5 samples...\n",
            "Processed 6 samples...\n",
            "Processed 7 samples...\n",
            "Processed 8 samples...\n",
            "Processed 9 samples...\n",
            "Processed 10 samples...\n",
            "Processed 11 samples...\n",
            "Processed 12 samples...\n",
            "Processed 13 samples...\n",
            "Processed 14 samples...\n",
            "Processed 15 samples...\n",
            "Processed 16 samples...\n",
            "Processed 17 samples...\n",
            "Processed 18 samples...\n",
            "Processed 19 samples...\n",
            "Processed 20 samples...\n",
            "Processed 21 samples...\n",
            "Processed 22 samples...\n",
            "Processed 23 samples...\n",
            "Processed 24 samples...\n",
            "Processed 25 samples...\n",
            "Processed 26 samples...\n",
            "Processed 27 samples...\n",
            "Processed 28 samples...\n",
            "Processed 29 samples...\n",
            "Processed 30 samples...\n",
            "Processed 31 samples...\n",
            "Processed 32 samples...\n",
            "Processed 33 samples...\n",
            "Processed 34 samples...\n",
            "Processed 35 samples...\n",
            "Processed 36 samples...\n",
            "Processed 37 samples...\n",
            "Processed 38 samples...\n",
            "Processed 39 samples...\n",
            "Processed 40 samples...\n",
            "Processed 41 samples...\n",
            "Processed 42 samples...\n",
            "Processed 43 samples...\n",
            "Processed 44 samples...\n",
            "Processed 45 samples...\n",
            "Processed 46 samples...\n",
            "Processed 47 samples...\n",
            "Processed 48 samples...\n",
            "Processed 49 samples...\n",
            "Processed 50 samples...\n",
            "Processed 51 samples...\n",
            "Processed 52 samples...\n",
            "Processed 53 samples...\n",
            "Processed 54 samples...\n",
            "Processed 55 samples...\n",
            "Processed 56 samples...\n",
            "Processed 57 samples...\n",
            "Processed 58 samples...\n",
            "Processed 59 samples...\n",
            "Processed 60 samples...\n",
            "Processed 61 samples...\n",
            "Processed 62 samples...\n",
            "Processed 63 samples...\n",
            "Processed 64 samples...\n",
            "Processed 65 samples...\n",
            "Processed 66 samples...\n",
            "Processed 67 samples...\n",
            "Processed 68 samples...\n",
            "Processed 69 samples...\n",
            "Processed 70 samples...\n",
            "Processed 71 samples...\n",
            "Processed 72 samples...\n",
            "Processed 73 samples...\n",
            "Processed 0 samples...\n",
            "Processed 1 samples...\n",
            "Processed 2 samples...\n",
            "Processed 3 samples...\n",
            "Processed 4 samples...\n",
            "Processed 5 samples...\n",
            "Processed 6 samples...\n",
            "Processed 7 samples...\n",
            "Processed 8 samples...\n",
            "Processed 9 samples...\n",
            "Processed 10 samples...\n",
            "Processed 11 samples...\n",
            "Processed 12 samples...\n",
            "Processed 13 samples...\n",
            "Processed 14 samples...\n",
            "Processed 15 samples...\n",
            "Processed 16 samples...\n",
            "Processed 17 samples...\n",
            "Processed 18 samples...\n",
            "Processed 19 samples...\n",
            "Processed 20 samples...\n",
            "Processed 21 samples...\n",
            "Processed 22 samples...\n",
            "Processed 23 samples...\n",
            "Processed 24 samples...\n",
            "Processed 25 samples...\n",
            "Processed 26 samples...\n",
            "Processed 27 samples...\n",
            "Processed 28 samples...\n",
            "Processed 29 samples...\n",
            "Processed 30 samples...\n",
            "Processed 31 samples...\n",
            "Processed 32 samples...\n",
            "Processed 33 samples...\n",
            "Processed 34 samples...\n",
            "Processed 35 samples...\n",
            "Processed 36 samples...\n",
            "Processed 37 samples...\n",
            "Processed 38 samples...\n",
            "Processed 39 samples...\n",
            "Processed 40 samples...\n",
            "Processed 41 samples...\n",
            "Processed 42 samples...\n",
            "Processed 43 samples...\n",
            "Processed 44 samples...\n",
            "Processed 45 samples...\n",
            "Processed 46 samples...\n",
            "Processed 47 samples...\n",
            "Processed 48 samples...\n",
            "Processed 49 samples...\n",
            "Processed 50 samples...\n",
            "Processed 51 samples...\n",
            "Processed 52 samples...\n",
            "Processed 53 samples...\n",
            "Processed 54 samples...\n",
            "Processed 55 samples...\n",
            "Processed 56 samples...\n",
            "Processed 57 samples...\n",
            "Processed 58 samples...\n",
            "Processed 59 samples...\n",
            "Processed 60 samples...\n",
            "Processed 61 samples...\n",
            "Processed 62 samples...\n",
            "Processed 63 samples...\n",
            "Processed 64 samples...\n",
            "Processed 65 samples...\n",
            "Processed 66 samples...\n",
            "Processed 67 samples...\n",
            "Processed 68 samples...\n",
            "Processed 69 samples...\n",
            "Processed 70 samples...\n",
            "Processed 71 samples...\n",
            "Processed 72 samples...\n",
            "Processed 73 samples...\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import pandas as pd\n",
        "import evaluate\n",
        "\n",
        "# Load Word Error Rate metric\n",
        "wer_metric = evaluate.load(\"wer\")\n",
        "\n",
        "def resample_audio(audio_array, orig_sr, target_sr=16000):\n",
        "    \"\"\"Resample audio to target sampling rate using torchaudio.\"\"\"\n",
        "    if orig_sr != target_sr:\n",
        "        # Convert to float32 before resampling\n",
        "        audio_tensor = torch.tensor(audio_array, dtype=torch.float32)\n",
        "        resampler = torchaudio.transforms.Resample(orig_freq=orig_sr, new_freq=target_sr)\n",
        "        return resampler(audio_tensor).numpy()\n",
        "    return audio_array\n",
        "\n",
        "def evaluate_whisper(model, processor, dataset, language):\n",
        "    \"\"\"Evaluate Whisper model on a dataset.\"\"\"\n",
        "    results = []\n",
        "\n",
        "    for i, item in enumerate(dataset):\n",
        "        # Resample audio if needed\n",
        "        audio_array = resample_audio(item[\"audio\"][\"array\"], item[\"audio\"][\"sampling_rate\"])\n",
        "\n",
        "        # Process audio\n",
        "        # Ensure input tensor matches model precision\n",
        "        input_features = processor(\n",
        "            audio_array,\n",
        "            sampling_rate=16000,\n",
        "            return_tensors=\"pt\"\n",
        "        ).input_features.to(dtype=next(model.parameters()).dtype, device=device)\n",
        "\n",
        "\n",
        "        # Generate token ids\n",
        "        forced_decoder_ids = processor.get_decoder_prompt_ids(language=language, task=\"transcribe\")\n",
        "        predicted_ids = model.generate(input_features.to(device), forced_decoder_ids=forced_decoder_ids)\n",
        "\n",
        "        # predicted_ids = model.generate(input_features, forced_decoder_ids=forced_decoder_ids)\n",
        "\n",
        "        # Decode token ids to text\n",
        "        transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "        # Compute WER\n",
        "        wer = wer_metric.compute(predictions=[transcription], references=[item[\"sentence\"]])\n",
        "\n",
        "        results.append({\n",
        "            \"reference\": item[\"sentence\"],\n",
        "            \"prediction\": transcription,\n",
        "            \"wer\": wer,\n",
        "            \"gender\": item[\"gender\"]\n",
        "        })\n",
        "\n",
        "        # if i % 10 == 0:\n",
        "        print(f\"Processed {i} samples...\")\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Evaluate on each language and gender group\n",
        "results = {}\n",
        "\n",
        "for lang in languages:\n",
        "    lang_results = {}\n",
        "    for pruning_level in pruning_levels:\n",
        "        print(f\"Evaluating {lang} with pruning level {pruning_level}...\")\n",
        "\n",
        "        # Evaluate separately on male and female datasets\n",
        "        male_df = evaluate_whisper(pruned_models[pruning_level], processor,\n",
        "                                   samples[lang]['male'], lang)\n",
        "        female_df = evaluate_whisper(pruned_models[pruning_level], processor,\n",
        "                                     samples[lang]['female'], lang)\n",
        "\n",
        "        # Store results\n",
        "        lang_results[pruning_level] = {\n",
        "            \"male\": male_df,\n",
        "            \"female\": female_df\n",
        "        }\n",
        "\n",
        "    results[lang] = lang_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "_KSN_vC5KkuH",
        "outputId": "28ba471b-094a-426d-8c08-049f474932f8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def analyze_gender_discrepancies(results):\n",
        "    \"\"\"Analyze WER differences between genders across pruning levels.\"\"\"\n",
        "    summary = {}\n",
        "\n",
        "    for lang in results:\n",
        "        lang_summary = []\n",
        "\n",
        "        for level in results[lang]:\n",
        "            male_wer = results[lang][level]['male']['wer'].mean()\n",
        "            female_wer = results[lang][level]['female']['wer'].mean()\n",
        "\n",
        "            # Calculate absolute difference (as in Figure 5 of the paper)\n",
        "            abs_diff = male_wer - female_wer\n",
        "\n",
        "            # Calculate relative difference (as in Figure 4 of the paper)\n",
        "            rel_diff = (male_wer - female_wer) / ((male_wer + female_wer) / 2) * 100\n",
        "\n",
        "            lang_summary.append({\n",
        "                'pruning_level': level,\n",
        "                'male_wer': male_wer,\n",
        "                'female_wer': female_wer,\n",
        "                'abs_diff': abs_diff,\n",
        "                'rel_diff': rel_diff\n",
        "            })\n",
        "\n",
        "        summary[lang] = pd.DataFrame(lang_summary)\n",
        "\n",
        "    return summary\n",
        "\n",
        "# Generate discrepancy analysis\n",
        "discrepancy_analysis = analyze_gender_discrepancies(results)\n",
        "\n",
        "# Plot the results (similar to Figure 4 and 5 in the paper)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot absolute differences\n",
        "plt.figure(figsize=(12, 6))\n",
        "for lang in languages:\n",
        "    plt.plot(\n",
        "        discrepancy_analysis[lang]['pruning_level'],\n",
        "        discrepancy_analysis[lang]['abs_diff'],\n",
        "        marker='o',\n",
        "        label=lang\n",
        "    )\n",
        "\n",
        "plt.axhline(y=0, color='r', linestyle='-', alpha=0.3)\n",
        "plt.xlabel('Pruning Level')\n",
        "plt.ylabel('WER difference (Male - Female)')\n",
        "plt.title('Absolute WER difference between male and female speakers')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "3eodKbyvKkuH",
        "outputId": "fe8b7200-236f-47b1-b233-971f470a5de7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def analyze_pruning_impact(results):\n",
        "    \"\"\"Analyze how pruning affects each gender group.\"\"\"\n",
        "    impact_summary = {}\n",
        "\n",
        "    for lang in results:\n",
        "        gender_impact = {'male': [], 'female': []}\n",
        "\n",
        "        # Get baseline (unpruned) performance\n",
        "        baseline_male_wer = results[lang][0]['male']['wer'].mean()\n",
        "        baseline_female_wer = results[lang][0]['female']['wer'].mean()\n",
        "\n",
        "        for level in pruning_levels:\n",
        "            if level == 0:  # Skip baseline\n",
        "                continue\n",
        "\n",
        "            male_wer = results[lang][level]['male']['wer'].mean()\n",
        "            female_wer = results[lang][level]['female']['wer'].mean()\n",
        "\n",
        "            # Calculate relative degradation\n",
        "            male_degradation = (male_wer - baseline_male_wer) / baseline_male_wer * 100\n",
        "            female_degradation = (female_wer - baseline_female_wer) / baseline_female_wer * 100\n",
        "\n",
        "            gender_impact['male'].append({\n",
        "                'pruning_level': level,\n",
        "                'wer': male_wer,\n",
        "                'degradation': male_degradation\n",
        "            })\n",
        "\n",
        "            gender_impact['female'].append({\n",
        "                'pruning_level': level,\n",
        "                'wer': female_wer,\n",
        "                'degradation': female_degradation\n",
        "            })\n",
        "\n",
        "        impact_summary[lang] = {\n",
        "            'male': pd.DataFrame(gender_impact['male']),\n",
        "            'female': pd.DataFrame(gender_impact['female'])\n",
        "        }\n",
        "\n",
        "    return impact_summary\n",
        "\n",
        "# Generate pruning impact analysis\n",
        "pruning_impact = analyze_pruning_impact(results)\n",
        "\n",
        "# Plot the degradation for each gender\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "for i, lang in enumerate(languages):\n",
        "    plt.subplot(2, 4, i+1)\n",
        "    plt.plot(\n",
        "        pruning_impact[lang]['male']['pruning_level'],\n",
        "        pruning_impact[lang]['male']['degradation'],\n",
        "        marker='o', label='Male', color='blue'\n",
        "    )\n",
        "    plt.plot(\n",
        "        pruning_impact[lang]['female']['pruning_level'],\n",
        "        pruning_impact[lang]['female']['degradation'],\n",
        "        marker='o', label='Female', color='red'\n",
        "    )\n",
        "    plt.title(f'Language: {lang}')\n",
        "    plt.xlabel('Pruning Level')\n",
        "    plt.ylabel('WER Degradation (%)')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    if i == 0:\n",
        "        plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "85b218c708814b0b87e9b890b2e39f7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1de4cc751f84c1a9d86c355fd7e65c7",
              "IPY_MODEL_346de9b952274147a7ce6ccd0aa9d207",
              "IPY_MODEL_9523ae69a81e4b5d9e6d9c0cbdec40db",
              "IPY_MODEL_9e7f16824fc345adb93168f1bd3b0db8",
              "IPY_MODEL_40aea8874d2243228d759818c65f43d2"
            ],
            "layout": "IPY_MODEL_cc07cb72d2e84d9bb35ae3ef186d83b4"
          }
        },
        "f1de4cc751f84c1a9d86c355fd7e65c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e217b4328dc241dcad51b126cc7e3cdb",
            "placeholder": "​",
            "style": "IPY_MODEL_d15d4a89e24846a581601e225ce8638f",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "346de9b952274147a7ce6ccd0aa9d207": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_9d74ec1fc30a45fa98b7e80828e4cfdc",
            "placeholder": "​",
            "style": "IPY_MODEL_a13b62b212764d3ca1a9b40a7c07b828",
            "value": ""
          }
        },
        "9523ae69a81e4b5d9e6d9c0cbdec40db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_d3b40884c87949c98e45c08e8e8f018a",
            "style": "IPY_MODEL_190448ea81544b839de18f0bce9a065b",
            "value": true
          }
        },
        "9e7f16824fc345adb93168f1bd3b0db8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_9ff63ccde3b447c3bdcbdb3c8029475b",
            "style": "IPY_MODEL_29d5183917ed46669e02fe4948e06845",
            "tooltip": ""
          }
        },
        "40aea8874d2243228d759818c65f43d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13de90f54251461a9ef73e3ab0b11aa2",
            "placeholder": "​",
            "style": "IPY_MODEL_8ab6ccaa3d614bdd8b5d14d55af37b47",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "cc07cb72d2e84d9bb35ae3ef186d83b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "e217b4328dc241dcad51b126cc7e3cdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d15d4a89e24846a581601e225ce8638f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d74ec1fc30a45fa98b7e80828e4cfdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a13b62b212764d3ca1a9b40a7c07b828": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3b40884c87949c98e45c08e8e8f018a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "190448ea81544b839de18f0bce9a065b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ff63ccde3b447c3bdcbdb3c8029475b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29d5183917ed46669e02fe4948e06845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "13de90f54251461a9ef73e3ab0b11aa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ab6ccaa3d614bdd8b5d14d55af37b47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}